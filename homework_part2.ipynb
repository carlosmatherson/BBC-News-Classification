{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfad969",
   "metadata": {
    "papermill": {
     "duration": 0.003946,
     "end_time": "2025-03-27T02:50:57.879634",
     "exception": false,
     "start_time": "2025-03-27T02:50:57.875688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Limitation(s) of sklearnâ€™s NMF Library \n",
    "\n",
    "DTSA 5510 - Unsupervised Algorithms in Machine Learning\n",
    "\n",
    "University of Colorado Boulder\n",
    "\n",
    "Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999119d2",
   "metadata": {
    "_cell_guid": "8f2214e6-933e-4f65-9650-ec9b8455747d",
    "_uuid": "b34f9e1c-f8d5-46bd-b740-6babc2041f69",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003072,
     "end_time": "2025-03-27T02:50:57.886530",
     "exception": false,
     "start_time": "2025-03-27T02:50:57.883458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 1\n",
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899e4792",
   "metadata": {
    "_cell_guid": "62a021de-a9bd-4802-a0c3-18d4c43593af",
    "_uuid": "2fd07f7c-e487-4498-b5ba-ee94b1b663b1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T02:50:57.894844Z",
     "iopub.status.busy": "2025-03-27T02:50:57.894486Z",
     "iopub.status.idle": "2025-03-27T02:51:00.647949Z",
     "shell.execute_reply": "2025-03-27T02:51:00.646709Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.760376,
     "end_time": "2025-03-27T02:51:00.650236",
     "exception": false,
     "start_time": "2025-03-27T02:50:57.889860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ba701",
   "metadata": {
    "_cell_guid": "83d42397-923a-49fd-a32a-9a69124d03e2",
    "_uuid": "21de88a3-5b94-43fe-bb51-7804a1fba632",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003661,
     "end_time": "2025-03-27T02:51:00.657898",
     "exception": false,
     "start_time": "2025-03-27T02:51:00.654237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Data\n",
    "\n",
    "Loading the same MovieLens 1M dataset from the homework. Luckily, it was hosted here on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887cf613",
   "metadata": {
    "_cell_guid": "d27d1597-2165-4c37-854a-483796769f54",
    "_uuid": "7ab9ad2f-01c3-4dcd-9f78-87c54f257f91",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T02:51:00.666261Z",
     "iopub.status.busy": "2025-03-27T02:51:00.665785Z",
     "iopub.status.idle": "2025-03-27T02:51:06.463186Z",
     "shell.execute_reply": "2025-03-27T02:51:06.462036Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.80383,
     "end_time": "2025-03-27T02:51:06.465306",
     "exception": false,
     "start_time": "2025-03-27T02:51:00.661476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('/kaggle/input/movielens-1m-dataset/users.dat',\n",
    "                       header=None, \n",
    "                       sep='::', \n",
    "                       names=['UserID','Gender','Age','Occupation','Zip-code'], \n",
    "                       engine='python',\n",
    "                       encoding='latin-1')\n",
    "\n",
    "\n",
    "movies_df = pd.read_csv('/kaggle/input/movielens-1m-dataset/movies.dat',\n",
    "                        header=None,\n",
    "                        sep='::',\n",
    "                        names=['MovieID', 'Title', 'Genre'], \n",
    "                        engine='python',\n",
    "                        encoding='latin-1')\n",
    "\n",
    "ratings_df = pd.read_csv('/kaggle/input/movielens-1m-dataset/ratings.dat',\n",
    "                         header=None,\n",
    "                         sep='::',\n",
    "                         names=['UserID','MovieID','Rating','Timestamp'], \n",
    "                         engine='python',\n",
    "                         encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b4ce6",
   "metadata": {
    "papermill": {
     "duration": 0.003246,
     "end_time": "2025-03-27T02:51:06.472248",
     "exception": false,
     "start_time": "2025-03-27T02:51:06.469002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I split the ratings data into a train subset (80%) and a test subset (20%). Then, I put it all together into a names tuple for convenience and print the first few rows of each data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c68b0e5",
   "metadata": {
    "_cell_guid": "1776f238-d340-4035-8dac-a99401a301c0",
    "_uuid": "97102643-a363-41d8-ab03-0021937cd69f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T02:51:06.480326Z",
     "iopub.status.busy": "2025-03-27T02:51:06.479940Z",
     "iopub.status.idle": "2025-03-27T02:51:06.601081Z",
     "shell.execute_reply": "2025-03-27T02:51:06.599813Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.127391,
     "end_time": "2025-03-27T02:51:06.602958",
     "exception": false,
     "start_time": "2025-03-27T02:51:06.475567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "\n",
      "    MovieID                               Title                         Genre\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "\n",
      "         UserID  MovieID  Rating  Timestamp\n",
      "788405    4716     2243       4  964618482\n",
      "927857    5605     3614       4  959297974\n",
      "442896    2730     1394       5  973262613\n",
      "99688      666      915       4  975642390\n",
      "422307    2557      608       3  973990434\n",
      "\n",
      "         UserID  MovieID  Rating   Timestamp\n",
      "871298    5263      748       2   961191306\n",
      "212761    1297     2268       5   974789441\n",
      "134537     869      333       4   999376445\n",
      "729728    4363      208       4   965185497\n",
      "709814    4258     1953       4  1007411197\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=19)\n",
    "\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(users_df, movies_df, train_df, test_df)\n",
    "\n",
    "print('\\n',data.users.head())\n",
    "print('\\n',data.movies.head())\n",
    "print('\\n',data.train.head())\n",
    "print('\\n',data.test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c9285",
   "metadata": {
    "_cell_guid": "9b9452c6-4e36-445b-88de-059241457a8f",
    "_uuid": "42930302-6a5a-4c21-82c7-93967287df6d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003523,
     "end_time": "2025-03-27T02:51:06.610197",
     "exception": false,
     "start_time": "2025-03-27T02:51:06.606674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### NMF Matrix Factorization Custom Implementation\n",
    "\n",
    "Initialized like the RecSys class from the original homework notebook. Has methods for building the rating matrix, fitting NMF, making predictions, and scoreing using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b28ec6",
   "metadata": {
    "_cell_guid": "cc76352e-e48f-4088-90d6-d5d8640e8ca7",
    "_uuid": "8c562eef-b442-430c-80ab-81cacb0b1602",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T02:51:06.618732Z",
     "iopub.status.busy": "2025-03-27T02:51:06.618248Z",
     "iopub.status.idle": "2025-03-27T02:51:06.631171Z",
     "shell.execute_reply": "2025-03-27T02:51:06.629710Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019385,
     "end_time": "2025-03-27T02:51:06.633191",
     "exception": false,
     "start_time": "2025-03-27T02:51:06.613806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "            self.data=data\n",
    "            self.allusers = list(self.data.users['UserID'])\n",
    "            self.allmovies = list(self.data.movies['MovieID'])\n",
    "            self.mid2idx = dict(zip(self.data.movies.MovieID,list(range(len(self.data.movies)))))\n",
    "            self.uid2idx = dict(zip(self.data.users.UserID,list(range(len(self.data.users)))))\n",
    "            self.Mr=self.rating_matrix()\n",
    "            self.W = None  # User factors\n",
    "            self.H = None  # Item factors\n",
    "            self.reconstructed = None  # Reconstructed matrix\n",
    "            self.n_components_ = None\n",
    "\n",
    "    def rating_matrix(self):\n",
    "\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.MovieID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.UserID]\n",
    "        rating_train = list(self.data.train.Rating)\n",
    "        \n",
    "        return csr_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies)))\n",
    "\n",
    "    \n",
    "    def fit_nmf(self, n_components=1, max_iter=200, beta_loss='frobenius', init='random', solver='cd'):\n",
    "        \n",
    "        Mr_dense = self.Mr.toarray()\n",
    "        \n",
    "        global_mean = Mr_dense[Mr_dense > 0].mean()\n",
    "        \n",
    "        # impute with global mean \n",
    "        Mr_filled = Mr_dense.copy()\n",
    "        Mr_filled[Mr_filled == 0] = global_mean\n",
    "        \n",
    "        # initialize and fit NMF model            \n",
    "        model = NMF(n_components=n_components, max_iter=max_iter, beta_loss=beta_loss, \n",
    "                    init=init, solver=solver,random_state=19)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.W = model.fit_transform(Mr_filled)\n",
    "        self.H = model.components_\n",
    "        self.n_components_ = model.n_components_\n",
    "        \n",
    "        # rebuild the ratings matrix\n",
    "        self.reconstructed = np.dot(self.W, self.H)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"NMF fitting time {elapsed}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_from_nmf(self, uid, mid):\n",
    "\n",
    "        if self.reconstructed is None:\n",
    "            return 3.0  \n",
    "        \n",
    "        user_idx = self.uid2idx[uid]\n",
    "        movie_idx = self.mid2idx[mid]\n",
    "        \n",
    "        # clip to range (1-5)\n",
    "        prediction = self.reconstructed[user_idx, movie_idx]\n",
    "        return np.clip(prediction, 1, 5)\n",
    "    \n",
    "    def predict(self):\n",
    "\n",
    "        uids = self.data.test['UserID'].values\n",
    "        mids = self.data.test['MovieID'].values\n",
    "        \n",
    "        predictions = np.array([self.predict_from_nmf(uid, mid) for uid, mid in zip(uids, mids)])\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.Rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959b2cf2",
   "metadata": {
    "_cell_guid": "e176eb69-c8b1-47f4-aec4-4f3042845c81",
    "_uuid": "6c55327b-eb63-4c08-b77e-005ad758e438",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T02:51:06.641335Z",
     "iopub.status.busy": "2025-03-27T02:51:06.641011Z",
     "iopub.status.idle": "2025-03-27T02:54:37.884994Z",
     "shell.execute_reply": "2025-03-27T02:54:37.883560Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 211.250209,
     "end_time": "2025-03-27T02:54:37.886940",
     "exception": false,
     "start_time": "2025-03-27T02:51:06.636731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF fitting time 0.456740140914917\n",
      "NMF with 1 components RMSE: 1.1737815382990575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF fitting time 26.7675199508667\n",
      "NMF with 50 components RMSE: 1.0726620197231886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF fitting time 59.95575976371765\n",
      "NMF with 100 components RMSE: 1.0983095865459571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF fitting time 114.30477476119995\n",
      "NMF with 150 components RMSE: 1.119522350478055\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 50, 100, 150]:\n",
    "\n",
    "        mf = MatrixFactorization(data)\n",
    "\n",
    "        mf.fit_nmf(n_components=k)\n",
    "\n",
    "        predictions = mf.predict()\n",
    "        rmse = mf.rmse(predictions)\n",
    "\n",
    "        print(f\"NMF with {mf.n_components_} components RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d5dfc",
   "metadata": {
    "_cell_guid": "a087eb4b-24d8-43b6-a1c7-8f94e32340af",
    "_uuid": "6f606639-6932-4a34-93ec-5574b4a9e8a8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004499,
     "end_time": "2025-03-27T02:54:37.895892",
     "exception": false,
     "start_time": "2025-03-27T02:54:37.891393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 2\n",
    "\n",
    "The NMF approach yielded high RMSE values. The best RMSE achieved was 1.07, which is within the range of values achieved with similarity based methods, but not particularly impressive. The table below shows each method used and their RMSE.\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3|1.26 |\n",
    "|Baseline, $Y_p=\\mu_u$|1.14 |\n",
    "|Content based, item-item|1.19 |\n",
    "|Collaborative, cosine|1.14 |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|0.98  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|0.99  |\n",
    "|Collaborative, jaccard, $M_r$|0.96|\n",
    "\n",
    "It is clear that the matrix factorization approach (RMSE 1.07) is much better than the baseline methods that imputed values with either the median rating (RMSE 1.26) or the mean rating (RMSE 1.14). Non-negative Matrix Factorization is also superior to the content based item-item (RMSE 1.19) and collaborative appraoch with cosine similarity (RMSE 1.14) methods. \n",
    "\n",
    "NMF falls short compared to collaboritve recommendation using jaccard similarity in general. Three strategies were used to construct the ratings (utility) matrix for the collaborative recommendation methods. The first was to use only the good ratings (>2 on a 1-5 scale), and this achieved an RMSE of 0.98. The second was to use only the existing ratings (>0), which achieved an RMSE of 0.99. The third was to use the data without applying a transformation to achieve the lowest RMSE of 0.96.\n",
    "\n",
    "The inferior performance can likely be attributed to NMF's inability to handle sparse data. The other recommendation methods can take advantage of sparse matrices, but NMF requires dense matrices and imputation. Also, the better-performing jaccard-based methods transform contuous ratings into binary, which may allow this approach to capture preference patterns more accurately than the continuous ratings used by NMF and the rest.\n",
    "\n",
    "Overall, NMF is too generic to compete with the more specialized recommendation systems. To improve the error, it may be beneficial to transform the utlity matrix to contain binary values as seen in the jaccard-based methods. Additionally, optimizing the hyperparameters can likely improve the capacity to recognize preference patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f61945",
   "metadata": {
    "papermill": {
     "duration": 0.003851,
     "end_time": "2025-03-27T02:54:37.904436",
     "exception": false,
     "start_time": "2025-03-27T02:54:37.900585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1114664,
     "sourceId": 1872300,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 223.63631,
   "end_time": "2025-03-27T02:54:38.629949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-27T02:50:54.993639",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
